{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "tf2-2-3-gpu.2-3.m59",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "autowrite_bidirectional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYY3Nb6iAAc"
      },
      "source": [
        "# Bidirectional approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ_wISHhiAAe"
      },
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKrp4LILiAAe"
      },
      "source": [
        "path_to_file = \"8_ways_data_science_can_help.txt\" #Enter article name here"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NYh3gYFiAAf"
      },
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcty61friAAf",
        "outputId": "52a2725b-4361-44b7-f7e6-45fad096522a"
      },
      "source": [
        "text = open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print(f'The length of the article is {len(text)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the article is 6999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsgOXOAQiAAf"
      },
      "source": [
        "data = text.lower().replace('\\xa0\\xa0','')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBOMSvyviAAg"
      },
      "source": [
        "data = text.lower().replace('\\xa0','')\n",
        "data = data.split(\".\")\n",
        "#data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFjUTyZfiAAg"
      },
      "source": [
        "tokenizer.fit_on_texts(data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "#print(tokenizer.word_index)\n",
        "#print(total_words)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGq7_5yViAAg",
        "outputId": "2fbadc84-d059-437a-ab88-348f92111641"
      },
      "source": [
        "print(total_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl0jWcBfiAAh"
      },
      "source": [
        "input_sequences = []\n",
        "for line in data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        #print(i)\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        #print(\"N_gram: \"+ n_gram_sequence)\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "#print(input_sequences)\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO8HnRu6VEzu"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.983):\n",
        "            print(\"\\nReached acceptable accuary!\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcoty07iAAh",
        "outputId": "7c72f03f-1547-4586-8a79-adc5e704a74a"
      },
      "source": [
        "callback = myCallback()\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 128, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(40)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(xs, ys, epochs=1000, verbose=1,callbacks=[callback])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "33/33 [==============================] - 9s 14ms/step - loss: 6.2484 - accuracy: 0.0235\n",
            "Epoch 2/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.8744 - accuracy: 0.0391\n",
            "Epoch 3/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.7325 - accuracy: 0.0341\n",
            "Epoch 4/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.6173 - accuracy: 0.0266\n",
            "Epoch 5/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.6569 - accuracy: 0.0433\n",
            "Epoch 6/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.5721 - accuracy: 0.0337\n",
            "Epoch 7/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.5241 - accuracy: 0.0395\n",
            "Epoch 8/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.5385 - accuracy: 0.0387\n",
            "Epoch 9/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.3532 - accuracy: 0.0455\n",
            "Epoch 10/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.2660 - accuracy: 0.0539\n",
            "Epoch 11/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.1609 - accuracy: 0.0543\n",
            "Epoch 12/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 5.1592 - accuracy: 0.0624\n",
            "Epoch 13/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 4.9320 - accuracy: 0.0972\n",
            "Epoch 14/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.9434 - accuracy: 0.0940\n",
            "Epoch 15/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.8541 - accuracy: 0.0897\n",
            "Epoch 16/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.7552 - accuracy: 0.1033\n",
            "Epoch 17/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 4.6971 - accuracy: 0.1040\n",
            "Epoch 18/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.5230 - accuracy: 0.1251\n",
            "Epoch 19/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 4.4871 - accuracy: 0.1391\n",
            "Epoch 20/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.4495 - accuracy: 0.1331\n",
            "Epoch 21/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.3898 - accuracy: 0.1465\n",
            "Epoch 22/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.2991 - accuracy: 0.1436\n",
            "Epoch 23/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.2104 - accuracy: 0.1487\n",
            "Epoch 24/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.1654 - accuracy: 0.1551\n",
            "Epoch 25/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 4.0287 - accuracy: 0.1947\n",
            "Epoch 26/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.9884 - accuracy: 0.1995\n",
            "Epoch 27/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.8647 - accuracy: 0.2120\n",
            "Epoch 28/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.7534 - accuracy: 0.2402\n",
            "Epoch 29/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.6926 - accuracy: 0.2473\n",
            "Epoch 30/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.6770 - accuracy: 0.2514\n",
            "Epoch 31/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.6044 - accuracy: 0.2640\n",
            "Epoch 32/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.4884 - accuracy: 0.2861\n",
            "Epoch 33/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.3696 - accuracy: 0.3216\n",
            "Epoch 34/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.4030 - accuracy: 0.3178\n",
            "Epoch 35/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.2341 - accuracy: 0.3629\n",
            "Epoch 36/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.1596 - accuracy: 0.3582\n",
            "Epoch 37/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 3.0893 - accuracy: 0.3903\n",
            "Epoch 38/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 3.0187 - accuracy: 0.4258\n",
            "Epoch 39/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.9867 - accuracy: 0.4224\n",
            "Epoch 40/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.8663 - accuracy: 0.4682\n",
            "Epoch 41/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.8135 - accuracy: 0.4675\n",
            "Epoch 42/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 2.7479 - accuracy: 0.5057\n",
            "Epoch 43/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.6856 - accuracy: 0.5078\n",
            "Epoch 44/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 2.6248 - accuracy: 0.5438\n",
            "Epoch 45/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.5614 - accuracy: 0.5553\n",
            "Epoch 46/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 2.4707 - accuracy: 0.5567\n",
            "Epoch 47/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.3573 - accuracy: 0.6159\n",
            "Epoch 48/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.3615 - accuracy: 0.6093\n",
            "Epoch 49/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.3011 - accuracy: 0.6170\n",
            "Epoch 50/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 2.1622 - accuracy: 0.6892\n",
            "Epoch 51/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 2.1242 - accuracy: 0.6761\n",
            "Epoch 52/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 2.0983 - accuracy: 0.6822\n",
            "Epoch 53/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.9926 - accuracy: 0.7204\n",
            "Epoch 54/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.9698 - accuracy: 0.7257\n",
            "Epoch 55/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.9180 - accuracy: 0.7322\n",
            "Epoch 56/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.8276 - accuracy: 0.7584\n",
            "Epoch 57/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.8186 - accuracy: 0.7557\n",
            "Epoch 58/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 1.7503 - accuracy: 0.7604\n",
            "Epoch 59/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.6777 - accuracy: 0.7872\n",
            "Epoch 60/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.7006 - accuracy: 0.7653\n",
            "Epoch 61/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.6529 - accuracy: 0.7782\n",
            "Epoch 62/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.5595 - accuracy: 0.8060\n",
            "Epoch 63/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.5675 - accuracy: 0.7935\n",
            "Epoch 64/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 1.5075 - accuracy: 0.8101\n",
            "Epoch 65/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 1.4957 - accuracy: 0.8237\n",
            "Epoch 66/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 1.4089 - accuracy: 0.8281\n",
            "Epoch 67/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.3356 - accuracy: 0.8639\n",
            "Epoch 68/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.3093 - accuracy: 0.8606\n",
            "Epoch 69/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.2487 - accuracy: 0.8569\n",
            "Epoch 70/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.2583 - accuracy: 0.8729\n",
            "Epoch 71/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 1.1868 - accuracy: 0.8641\n",
            "Epoch 72/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.1699 - accuracy: 0.8747\n",
            "Epoch 73/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.0605 - accuracy: 0.9081\n",
            "Epoch 74/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.0335 - accuracy: 0.9156\n",
            "Epoch 75/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 1.0563 - accuracy: 0.9011\n",
            "Epoch 76/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.9838 - accuracy: 0.9141\n",
            "Epoch 77/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.9924 - accuracy: 0.9120\n",
            "Epoch 78/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.9556 - accuracy: 0.9054\n",
            "Epoch 79/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.9361 - accuracy: 0.9244\n",
            "Epoch 80/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.9054 - accuracy: 0.9176\n",
            "Epoch 81/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.8633 - accuracy: 0.9271\n",
            "Epoch 82/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.8500 - accuracy: 0.9268\n",
            "Epoch 83/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.8382 - accuracy: 0.9305\n",
            "Epoch 84/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.7821 - accuracy: 0.9303\n",
            "Epoch 85/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.7319 - accuracy: 0.9535\n",
            "Epoch 86/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.7393 - accuracy: 0.9480\n",
            "Epoch 87/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.7217 - accuracy: 0.9427\n",
            "Epoch 88/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.7403 - accuracy: 0.9363\n",
            "Epoch 89/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.9506\n",
            "Epoch 90/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.9540\n",
            "Epoch 91/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.6467 - accuracy: 0.9532\n",
            "Epoch 92/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.6006 - accuracy: 0.9619\n",
            "Epoch 93/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.5908 - accuracy: 0.9671\n",
            "Epoch 94/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.6040 - accuracy: 0.9617\n",
            "Epoch 95/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.5764 - accuracy: 0.9631\n",
            "Epoch 96/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.5486 - accuracy: 0.9628\n",
            "Epoch 97/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.5564 - accuracy: 0.9605\n",
            "Epoch 98/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.5151 - accuracy: 0.9680\n",
            "Epoch 99/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.5069 - accuracy: 0.9684\n",
            "Epoch 100/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.5022 - accuracy: 0.9603\n",
            "Epoch 101/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.5012 - accuracy: 0.9675\n",
            "Epoch 102/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.4932 - accuracy: 0.9615\n",
            "Epoch 103/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.4611 - accuracy: 0.9670\n",
            "Epoch 104/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.4392 - accuracy: 0.9763\n",
            "Epoch 105/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.4330 - accuracy: 0.9764\n",
            "Epoch 106/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.4212 - accuracy: 0.9763\n",
            "Epoch 107/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.4248 - accuracy: 0.9684\n",
            "Epoch 108/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.3920 - accuracy: 0.9674\n",
            "Epoch 109/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.9708\n",
            "Epoch 110/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.3807 - accuracy: 0.9736\n",
            "Epoch 111/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.3548 - accuracy: 0.9827\n",
            "Epoch 112/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3670 - accuracy: 0.9810\n",
            "Epoch 113/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.3593 - accuracy: 0.9739\n",
            "Epoch 114/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3495 - accuracy: 0.9725\n",
            "Epoch 115/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3237 - accuracy: 0.9796\n",
            "Epoch 116/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.3357 - accuracy: 0.9769\n",
            "Epoch 117/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3145 - accuracy: 0.9853\n",
            "Epoch 118/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3126 - accuracy: 0.9836\n",
            "Epoch 119/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3129 - accuracy: 0.9849\n",
            "Epoch 120/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3073 - accuracy: 0.9888\n",
            "\n",
            "Reached acceptable accuary!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ahspg7ViAAh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gzNhhy94iAAi",
        "outputId": "01167a25-635a-471c-f343-ef49f277eb1d"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgJX0CPCiAAi",
        "outputId": "97aeb507-92a8-4c9e-fdeb-f2db132a2335"
      },
      "source": [
        "#seed_text = \"Using data science to optimize your budget\"\n",
        "#seed_text = \"rich customer experience has always been an important factor\"\n",
        "seed_text = \"This can be highly beneficial\"\n",
        "next_words = 20\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list],maxlen=max_sequence_len-1,padding='pre')\n",
        "    predicted = model.predict_classes(token_list,verbose=0)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "This can be highly beneficial as it tells the marketer exactly which channel and medium are delivering proper returns cross channel micro copy on landing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDDTtGAJiAAi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}